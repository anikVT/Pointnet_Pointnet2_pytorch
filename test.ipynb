{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from models.pointnet2_cls_msg import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os  # Import os to easily manipulate paths\n",
    "\n",
    "# This should be the directory that contains your module, not the module file itself\n",
    "package_directory = os.path.dirname('/home/hani/GitHub/PCR_practice/Old_notebooks')\n",
    "\n",
    "# Add the directory to sys.path\n",
    "if package_directory not in sys.path:\n",
    "    sys.path.append(package_directory)\n",
    "\n",
    "# Now you can import your module as if it were in the same directory\n",
    "from Old_notebooks.simdata_utils import *\n",
    "from Old_notebooks import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_pnpp_original  = 'log/classification/pointnet2_msg_normals/checkpoints/best_model.pth'\n",
    "checkpoint_path_pnpp_mdnetc = '/home/hani/GitHub/PCR_practice/Old_notebooks/models/mdnet_40_C_pnpp_da/model_best_test.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_pnpp_original = torch.load(checkpoint_path_pnpp_original, map_location=torch.device('cpu'))\n",
    "checkpoint_pnpp_mdnetc = torch.load(checkpoint_path_pnpp_mdnetc, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'instance_acc', 'class_acc', 'model_state_dict', 'optimizer_state_dict'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_pnpp_original.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cfg', 'epoch', 'model_state', 'optimizer_state', 'lr_sched_state', 'bnm_sched_state', 'test_perf'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_pnpp_mdnetc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the state dict of the model\n",
    "\n",
    "model_state_dict_pnpp_original = checkpoint_pnpp_original['model_state_dict']\n",
    "model_state_dict_pnpp_mdnetc = checkpoint_pnpp_mdnetc['model_state']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load architecture of the model original\n",
    "model_pnpp_original  = get_model(40,normal_channel=True)\n",
    "model_pnpp_original.load_state_dict(model_state_dict_pnpp_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set the model to evaluation mode\n",
    "#model_pnpp_original.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances 1300\n"
     ]
    }
   ],
   "source": [
    "### loading data\n",
    "# Example usage\n",
    "#hdf5_file = 'partial_mdnet_40.h5'\n",
    "hdf5_file = '/home/hani/GitHub/PCR_practice/Old_notebooks/mdnet_sorted_no_corr_clean.h5'\n",
    "#hdf5_file = 'combined.h5'\n",
    "# Reading the data\n",
    "data = load_entire_dataset(hdf5_file)\n",
    "\n",
    "print('Instances', len(list(data.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract source and target point clouds ###\n",
    "src_dst_data =  extract_src_dst(data)\n",
    "part_dst_data = extract_partViews_dst(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part_dst_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_source = part_dst_data['airplane_O10_V1']\n",
    "part_dst = part_dst_data['airplane_O15_Vdst'] \n",
    "part_dst = pc_normalize(part_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### data is loaded and ready to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_features = estimate_robust_normals_using_open3d(smaple_data_with_normals_ds[:,:3])  # Replace with actual features if available\n",
    "#additional_features = np.random.rand(part_dst.shape[0], 3)  # Replace with actual features if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_point_cloud_np = np.concatenate([(smaple_data_with_normals_ds[:,:3]),additional_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 6)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_point_cloud_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud_tensor = torch.tensor(augmented_point_cloud_np, dtype=torch.float).transpose(0, 1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 2500])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_cloud_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "with torch.no_grad():\n",
    "    prediction, l3_pts = model_pnpp_original.forward(point_cloud_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.1526e-07, -1.7786e+01, -1.8443e+01, -1.8961e+01, -2.5635e+01,\n",
       "         -2.5560e+01, -1.7568e+01, -1.6996e+01, -2.3804e+01, -1.9274e+01,\n",
       "         -2.2335e+01, -1.8848e+01, -1.9226e+01, -2.2030e+01, -1.9227e+01,\n",
       "         -2.1648e+01, -2.0232e+01, -1.7183e+01, -2.0889e+01, -2.1294e+01,\n",
       "         -1.8363e+01, -1.6360e+01, -1.6795e+01, -1.9659e+01, -1.8857e+01,\n",
       "         -1.9180e+01, -1.6710e+01, -1.6694e+01, -1.9954e+01, -1.7378e+01,\n",
       "         -1.7797e+01, -2.0409e+01, -2.3182e+01, -1.7018e+01, -1.6416e+01,\n",
       "         -1.6925e+01, -2.2164e+01, -2.7410e+01, -2.5723e+01, -1.7804e+01]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "_, predicted_class = torch.max(prediction, 1)  # Returns the value and index of the maximum value in each row\n",
    "# or\n",
    "predicted_class = prediction.argmax(1)  # Directly returns the index of the maximum value in each row\n",
    "\n",
    "print(predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 1])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3_pts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 2500])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_cloud_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz1pcl_xyz(part_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Load new dataset resampled with normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_to_numpy(filepath):\n",
    "    \"\"\"\n",
    "    Reads a text file with point cloud data into a numpy array.\n",
    "\n",
    "    Parameters:\n",
    "    - filepath: str, the path to the text file containing the data.\n",
    "\n",
    "    Returns:\n",
    "    - data: numpy.ndarray, an array of shape (n, 6) where n is the number of points.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store the data points\n",
    "    data_points = []\n",
    "\n",
    "    # Open the file and read line by line\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split each line into components, convert to float, and append to the list\n",
    "            point = [float(value) for value in line.strip().split(',')]\n",
    "            data_points.append(point)\n",
    "\n",
    "    # Convert the list of data points into a numpy array\n",
    "    data = np.array(data_points)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_path = '/home/hani/GitHub/PCR_practice/modelnet40_normal_resampled/airplane/airplane_0025.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaple_data_with_normals = read_data_to_numpy(sample_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaple_data_with_normals_ds = downsample_data_ndarray(smaple_data_with_normals,100,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz1pcl_xyz(smaple_data_with_normals_ds[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz1pcl_xyz(estimate_robust_normals_using_open3d(smaple_data_with_normals_ds[:,:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz1pcl_xyz(project_to_unit_sphere(smaple_data_with_normals_ds[:,:3])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pc_normalize(pc):\n",
    "    centroid = np.mean(pc, axis=0)\n",
    "    pc = pc - centroid\n",
    "    m = np.max(np.sqrt(np.sum(pc**2, axis=1)))\n",
    "    pc = pc / m\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz1pcl_xyz(pc_normalize(smaple_data_with_normals_ds[:,:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz1pcl_xyz(smaple_data_with_normals_ds[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnet2pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
